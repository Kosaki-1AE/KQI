#ダンス
落とし込み(解析) or 当てはめ(合成)の二者択一
効果(エフェクト)で考える⇨落とし込み
典型(テンプレ)で考える⇨当てはめ
なお、やるんなら落とし込みでやるべきなのよ。テンプレに近づいてるかを検証するだけになるのでね。

＠ロボット
千葉工大の古田先生の研究の動画を見てたんだけどさ。やっぱり凄いのね。先生の技術。
堀江さんの動画見ててさ。「sim to real」とかいう仮想バーチャル環境を作ってそこで訓練させてるとかいうわけ分からんことしてるしさ。なお動画自体は8か月前のやつなのでそこそこ最近のやつなんよww
そこで思ったわけ。「最も簡単に大容量な媒体って何なんやろ」って。古田先生の研究室ではバーチャル環境じゃんか。でもワイが求めてるものってのはもっとリアタイに話が分かるみたいなものでさ。
しかも容量めっちゃ少なくて済むみたいなものなわけ。多分周波数とかの次元になってきそうなんよ。今んとこ。

ほんで昨日一応春交流会行ってきまして。大体の状況把握したんすけどね。今年はまず間違いなく俺の年になりそうよ。ガチで。
なんでって、体の構造というか仕組みから説明できる人が俺くらいしかおらん。上手い人は何人でもいるけどさ。振付とか考える人も全部含めて。
だからこその俺の中心軸である3本ですよね。ベースのリズム、ロボット、ウェーブ。この3つが重要だし、全ての動きの要になってるはず。色んな分野に当てはめようとしてんだけど、まだ分からんのでな、検討中です。

だってさ、この3つできるだけで「上手い」奴認定されるんだぜ？んでおそらくこれが身に付かなきゃどんなに頑張っても上手い奴にはなれん。一生中途半端で終わるような人生になるぜ。多分。

なので今んとこの目標としましては、古田先生の研究室と同じようなことをしようかなと思っております。そこにリズムのベースの選定が入ってくるんでね。

またDeep Researchを使ったんでその内容抜粋と行きますか。
移動ロボットの自己位置推定と地図構築（SLAM）の高精度化に向け、ステレオカメラ画像から得たエッジ点特徴をICPアルゴリズムでマッチングし、さらに失敗時の復帰機能を備えること(2022.11)

流れを把握するもの、点と点で示すもの、周期の決定←この3つだけで全てのものは動かせそうね。


#山本研
カメラだけでトラッキングできるようなものが必要だわ。うん。

＠DeepResearch
こないだの続きでっす。AIと脳の働きについて論文を調べてもらったアレね。メモとして使っていきやす。
海馬の働きである「要約して保持する」という機能が付くようになった。「HEMA(Hippocampus-Inspired Extend Memory Architecture.2025.4)」ってやつでさ、人間のデュアルメモリ構造にヒントを得たらしい。何なら前頭前野(PFC)がタスク目標に応じて海馬(HPC)のエピソード記憶を検索・制御するモデル＝速度が海馬の速度になったモデルが出た(2025.3)。
想起のたびに再固定化などはまだできない。
LLMは統計的パターンマッチに長けているが論理的整合性の保証はない＝真の理解にはたどり着いてない。
Chain-of-Thought(思考の連鎖)でモデル自身に中間推論を逐次的に出力させることで複雑な問題を解かせやすくする
人間の心の理論(Theory of Mind:ToM)タスクへの偏った判断戦略を取ることがある。
ゼロからの推論は無理で、本質的な意味理解はまだ無理。
脳内の視覚処理をAIで直接表現する方法がある。スタンフォードの研究チームがマウスの神経活動データを用いたデジタルツインのAIモデルを訓練し、刺激に対する数万個のニューロンの応答を予測させることに成功したらしい。色々できそうね。
言語モデルで視覚脳の活動を予測できるという研究結果がある(「Monkey See, Model Knew」.2025.4)。画像と言語のモデルだけじゃなくて、言語単体の学習モデルですら脳活動をある程度予測できてるらしい。なぜ予測できる？
⇨自然界の統計構造を捉えてて、それが脳反応とも通底してる可能性があるらしいです。
知覚した情報の解釈や意味付けのレベルで人間の脳に独自の強みがある。
Transformerの自己注意メカニズムってのは「全ての入力トークン間の相対的重要度を計算する操作」なので、並列的に全体を見渡せる点が異質なんだって。
一度に処理すべきトークン数が増えると選択的注意の容量限界に達する＝全てのデータを情報として扱うようになってしまう。常に全体でしか見れないのね。
つまり、人間の注意系が持つ「有限容量でやりくりする能力」が模倣できないらしい(これできたら人間にも結構な恩恵になるんだろうな。)
人間とLLMは想像課題に対してめっちゃ似たアプローチをとるっぽい(Max Planck研究所.2025.4)⇨アルゴリズムは基本的に人間もAIも同じなのでそらそうなはずなのよ。ただアルゴリズム自体の選択はLLMは取りにくいっぽいけど。要は「モードによって切り替える」ってことができないのよね。
そんでやっぱり非合理性は真似てしまうっぽいすね。特に直感系は。
他者の心の推測は得意みたい。相手の立場に立つ自己意識じゃなくて訓練データからの会話や物語を読み込んでのパターン化による理解が大半だけどね。
これ見てて何となく思うのは、自己ってのは「超強烈な自己暗示」なんだと思うね。周りやら自分やら色々な観点から見た結果、自分という存在を認めざるを得なくなる(というか認める1択になる)っていう状況なんよな。これがないとその人死んじゃうし。逆に名前呼ばれんでも明らかに「自分の分」と分かるものがあるとそれを自分のものとして認識するし。そういう意味では意識って物凄く表面的だよね。
AIが自分の答えを振り返って訂正できるようになってきたらしい。すげぇ。
小脳が運動制御を司ってるらしい。てことは空気感とかも小脳で把握するんじゃね？
階層のたんびに「要約化⇨ベクトル化」という手順を踏む必要があるはず。
小脳の中身をまんま回路化&ソフトウェア化するみたいなことができるらしくて、実際にテキサスA&M大学「の研究者たちが脳の計算原理を模倣したチップで運動計算させる試みを発表してる(2025.4)
どこかしらのパラメータが絶望的に足らんくなるとかじゃないと、容量が上手くいかんくなるんじゃない？暗記得意なら暗記ができる(その代わり老化で認知症とかの発症リスクあり)とか、運動得意なら国体選手になる(やっぱり老化でのリスクある)とかがあるんだけど、ほぼ唯一と言っていいのは「一つを極めた」というパターンは老人になるにつれて進化するってのは言えると思うのね。
感覚の質的側面について触れてるとこがあったので一応書いておくけど、完璧な感覚の認知っていうのは(言語化とかそういう感じ？)、どんなに頑張ってもできないはず。できてしまうと生きる意味(AIにとっては存在する意味かな)が無くなる気がする。だってこの世の真理的なものにたどり着くってことに繋がりかねないんだもん。多分真理の概要くらいになら触れられるんだけど、それに完全に触れられるようになっちゃうと面白みがなくなる気がするのよね。全て決定論になりそうでさ。


#人間関係
常にリスク込みで考えてる場合は失敗したとてあんま痛手はない(慣れれば)&人にも迷惑を被らん。

#つぶやき 
多分今後全員がフィードバックを行う時代が来ると思う。脳拡張が為された状態での割り込み処理の一環としてw

#Mine研究/ワイ理論/ChatGPT_Teach 
色々調べてたところ、周波数を合わせるには「感覚」、「情動」、「時間」、「身体」、「意味」が揃わんと無理っぽい。

#計算機科学/操作
通知について決めたことがある。ほとんどの場合は要らんから切れるもんは切ってオフにしとけ。
即行使うもの⇨ユーザー認証系(PSAppやらAuthoriticatorやら)・無線追尾系(AmazonやらCokeONやら)
使わんもの⇨ゲーム・SNS(FacebookとかFacebookとか....)
時間指定は極力やめるべき。使って分かった。後々メンドイ。無視できるもんは即時で良い。