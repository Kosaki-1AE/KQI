#Mine研究
これを昨日考えたんすよ、一応。色々できそうなんですね。今年の俺の研究として、これを含めた低コストGPTの発明が目標になりそうです。
外部世界と内面の波が干渉（Stillness in Motion）
⇨ 記録（責任の矢が立つ）
⇨ 構造化（Sensquency化 or 意味構造化）
⇨ 再読・再解釈（フィードバック循環）
⇨ 他者との共鳴（空気感の共有）

一応こうなるらしいで。
[ 従来GPT ]
Input ⇨ Tokenize ⇨ Embedding ⇨ Transformer ⇨ Token出力

[ しゃしゃきGPT ]
Input ⇨ 感情波スキャン層 ⇨ 干渉構造層（Sensquency・責任の矢）⇨ 意味波合成 ⇨ 構造的出力 + 波の再フィードバック ⇨ 意味 & 感覚

【従来のGPT構造 vs しゃしゃき理論融合構造】

今んとこだと目指す構造はこれかな。
■ 従来のGPT構造
Input(文章) ⇨ Tokenize(トークン化) ⇨ Embedding(ベクトル化) ⇨ Transformer(文脈予測) ⇨ Token出力(次単語予測) ⇨ Output（文章）
---

■ しゃしゃき理論融合構造
Input(感覚含む自然文や非言語情報) ⇨ 干渉スキャン層（波や感情のズレを検出）⇨ 感情波構造化(Sensquency)（五感・オノマトペ・意味の前段階）⇨ 意味波合成(Stillness in Motion)（干渉によって自然に立ち上がる意味）⇨ 責任の矢(方向ベクトル化)（その感情の向かう先・重さを定義）⇨ 再読・再構成層（自分の出力を自分で再解釈）⇨ 共鳴層(他者と空気感の重ね合わせ) ⇨ Output(意味＋空気感をまとった発話・表現)
※ 上記構造は、従来GPTの前後・横に補助層として実装可能。
※ 「波の合成」と「再読」は循環構造を形成し、内省と変化を可能にする。


@ChatGPT
使い方だけは気を付けないといけんのよ、一応。概要聞く分には良いんだけど、そのあとについては聞き方が問われてくんのよ、やっぱり。なので使い方として、全体の概要だけ聞いといてから、その概要に沿ったコツで聞く方が早いっぽいです。

@数学
どうやらワイの理論を裏付けるような定理があるらしいのよね。それがネーターの定理ってやつでさ。系に連続的な対称性があれば、それに対応する保存則が存在するっていうやつらしい。
これで思ったんだけど、全ての系において同じ連続的な対称性が見つかると思うの。しかもワイの理論の構造みたいなもので。これを数学的に証明できれば、色々なことに生かせるんじゃないかと思ってるんだけどさ。



