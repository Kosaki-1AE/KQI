{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOYNgsNlgBTW0z/La3oJ3+4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5mtUk4-LcFZf","executionInfo":{"status":"ok","timestamp":1766011099835,"user_tz":-540,"elapsed":2921,"user":{"displayName":"零一真","userId":"13547062280887801150"}},"outputId":"e5a7580a-45af-4126-d9cd-4cf020964c30"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"]}],"source":["!pip install torch"]},{"cell_type":"code","source":["import math\n","from dataclasses import dataclass\n","from enum import Enum, auto\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class Action(Enum):\n","    STAY_STILLNESS = auto()   # その層に留まる（保留）\n","    GO_NEXT = auto()          # 次の層へ進む\n","    GO_BACK = auto()          # 1つ戻る（再初期化の一部）\n","    ASK_CLARIFY = auto()      # 聞き直し（外部に質問）\n","    DECODE = auto()           # 出力してよい（生成へ）\n","\n","@dataclass\n","class ControllerConfig:\n","    # 「迷い」指標（logits entropy）\n","    ent_high: float = 6.0     # これ以上なら迷いすぎ →止まる/聞き直し\n","    ent_low: float = 3.0      # これ以下なら十分自信 → decode許可候補\n","\n","    # 「落ち着き」指標（Δh：層間の変化量）\n","    dh_small: float = 0.20    # これ以下なら落ち着いた（Stillness成立）\n","    dh_large: float = 0.80    # これ以上なら暴れてる（戻る/止まる）\n","\n","    # 行動の優先度・安全装置\n","    max_stay_steps: int = 3   # 止まり続けたら聞き直しへ\n","    allow_decode: bool = True\n","\n","class GSMCController:\n","    \"\"\"\n","    metrics を見て action を返すコントローラ。\n","    - entropy（必須級）：迷い度\n","    - delta_h（任意）：落ち着き度（層変化）\n","    - step_in_layer（任意）：同じ層に留まった回数\n","    \"\"\"\n","    def __init__(self, cfg: ControllerConfig | None = None):\n","        self.cfg = cfg or ControllerConfig()\n","\n","    def decide(self, metrics: dict) -> Action:\n","        \"\"\"\n","        metrics例:\n","          {\n","            \"entropy\": float or torch.Tensor scalar,\n","            \"delta_h\": float or torch.Tensor scalar (optional),\n","            \"step_in_layer\": int (optional),\n","            \"phase\": \"stillness\" | \"coherence\" | \"motion\" | ... (optional)\n","          }\n","        \"\"\"\n","        ent = metrics.get(\"entropy\", None)\n","        dh  = metrics.get(\"delta_h\", None)\n","        stay_steps = int(metrics.get(\"step_in_layer\", 0))\n","        phase = metrics.get(\"phase\", None)\n","\n","        # tensor -> float\n","        if isinstance(ent, torch.Tensor):\n","            ent = float(ent.detach().cpu().item())\n","        if isinstance(dh, torch.Tensor):\n","            dh = float(dh.detach().cpu().item())\n","\n","        # 0) entropy無いと判断できないので保留\n","        if ent is None:\n","            return Action.STAY_STILLNESS\n","\n","        # 1) 迷いが高すぎる：止まる or 聞き直し\n","        if ent >= self.cfg.ent_high:\n","            if stay_steps >= self.cfg.max_stay_steps:\n","                return Action.ASK_CLARIFY\n","            return Action.STAY_STILLNESS\n","\n","        # 2) Δhが取れている場合の安全装置\n","        if dh is not None:\n","            # 暴れてる：戻る or 止める\n","            if dh >= self.cfg.dh_large:\n","                return Action.GO_BACK\n","            # 落ち着いた：次へ進む（Stillness成立）\n","            if dh <= self.cfg.dh_small:\n","                # Coherenceフェーズなら decode 判定へ寄せる\n","                if phase == \"coherence\" and self.cfg.allow_decode and ent <= self.cfg.ent_low:\n","                    return Action.DECODE\n","                return Action.GO_NEXT\n","\n","        # 3) entropyが十分低い（自信がある）なら decode（ただし許可制）\n","        if self.cfg.allow_decode and ent <= self.cfg.ent_low:\n","            # phaseが指定されてるなら coherence でのみ decode するのが安全\n","            if phase is None or phase == \"coherence\":\n","                return Action.DECODE\n","            # coherence以外なら一旦次へ（出力は保留）\n","            return Action.GO_NEXT\n","\n","        # 4) 中間：とりあえず次へ\n","        return Action.GO_NEXT\n","\n","def last_token_entropy(logits: torch.Tensor, eps: float = 1e-9) -> torch.Tensor:\n","    # logits: (B, T, V)\n","    p = torch.softmax(logits[:, -1, :], dim=-1)          # (B, V)\n","    ent = -(p * (p + eps).log()).sum(dim=-1)             # (B,)\n","    return ent.mean()  # とりまバッチ平均（scalar）\n","def token_entropy_from_logits(logits: torch.Tensor, eps: float = 1e-9):\n","    p = torch.softmax(logits, dim=-1)\n","    ent = -(p * (p + eps).log()).sum(dim=-1)   # (B, T)\n","    return ent\n","\n","# ----------------------------\n","# Positional Encoding　経験則をまんま持ってきたものがこれ。ようやくできるようになったわ。\n","# ----------------------------\n","class PositionalEncoding(nn.Module): #意味のある位置情報を埋め込みに追加する\n","    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n","        super().__init__()\n","        self.dropout = nn.Dropout(dropout)\n","\n","        pe = torch.zeros(max_len, d_model)  # (max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)  # (max_len, 1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float32) * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)  # even\n","        pe[:, 1::2] = torch.cos(position * div_term)  # odd\n","\n","        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n","        self.register_buffer(\"pe\", pe)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        \"\"\"\n","        x: (batch, seq_len, d_model)\n","        \"\"\"\n","        seq_len = x.size(1)\n","        x = x + self.pe[:, :seq_len, :]\n","        return self.dropout(x)\n","\n","\n","# ----------------------------\n","# Masks\n","# ----------------------------\n","def generate_square_subsequent_mask(sz: int, device=None) -> torch.Tensor: #注目すべき未来の情報を隠すためのマスク\n","    \"\"\"\n","    Causal mask for decoder self-attn.\n","    Returns (sz, sz) where upper triangle is -inf.\n","    \"\"\"\n","    device = device or torch.device(\"cpu\")\n","    mask = torch.full((sz, sz), float(\"-inf\"), device=device)\n","    mask = torch.triu(mask, diagonal=1)\n","    return mask\n","\n","def make_padding_mask(tokens: torch.Tensor, pad_id: int) -> torch.Tensor:\n","    \"\"\"\n","    tokens: (batch, seq_len)\n","    returns: (batch, seq_len) True where PAD\n","    \"\"\"\n","    return tokens.eq(pad_id)\n","\n","def layer_delta_h(hiddens: list[torch.Tensor]) -> torch.Tensor:\n","    \"\"\"\n","    hiddens: list of (B, L, D)\n","    returns: scalar tensor（平均Δh）\n","    \"\"\"\n","    if len(hiddens) < 2:\n","        return torch.tensor(0.0, device=hiddens[0].device)\n","    dh = []\n","    for i in range(1, len(hiddens)):\n","        # (B,L,D) -> まずDのノルム → (B,L) → 平均\n","        d = (hiddens[i] - hiddens[i-1]).norm(p=2, dim=-1).mean()\n","        dh.append(d)\n","    return torch.stack(dh).mean()\n","\n","def train_step(model, optimizer, src, tgt, pad_id=0):\n","    \"\"\"\n","    src: (B, S)\n","    tgt: (B, T)  ※BOS込みの想定でも、無い想定でもOK（ここではシンプルにランダム）\n","    \"\"\"\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    # teacher forcing 用に 1個ずらす\n","    tgt_in  = tgt[:, :-1]   # (B, T-1)\n","    tgt_out = tgt[:, 1:]    # (B, T-1)\n","\n","    logits = model(src, tgt_in)  # (B, T-1, V)\n","\n","    # PADはlossから除外\n","    loss = F.cross_entropy(\n","        logits.reshape(-1, logits.size(-1)),\n","        tgt_out.reshape(-1),\n","        ignore_index=pad_id\n","    )\n","\n","    loss.backward()\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # 任意だけど安定する\n","    optimizer.step()\n","    return loss.item(), logits\n","\n","@torch.no_grad()\n","def measure_metrics(model, src, tgt_in, pad_id=0):\n","    model.eval()\n","\n","    device = src.device\n","    src_pad = make_padding_mask(src, pad_id)\n","    tgt_pad = make_padding_mask(tgt_in, pad_id)\n","    tgt_mask = generate_square_subsequent_mask(tgt_in.size(1), device=device)\n","\n","    memory, _ = model.encode_with_layers(src, src_key_padding_mask=src_pad)\n","    dec_out, dec_h = model.decode_with_layers(\n","        tgt_in, memory,\n","        tgt_mask=tgt_mask,\n","        tgt_key_padding_mask=tgt_pad,\n","        memory_key_padding_mask=src_pad,\n","    )\n","\n","    logits = model.generator(dec_out)\n","    ent_last_mean = last_token_entropy(logits)      # scalar tensor\n","    dh_dec = layer_delta_h(dec_h)                   # scalar tensor\n","    return float(ent_last_mean), float(dh_dec), logits.shape\n","\n","# ----------------------------\n","# Full Transformer (Embedding -> Encoder -> Decoder -> Linear)\n","# ----------------------------\n","class TransformerSeq2Seq(nn.Module):\n","    def __init__(\n","        self,\n","        src_vocab_size: int,\n","        tgt_vocab_size: int,\n","        d_model: int = 512,\n","        nhead: int = 8,\n","        num_encoder_layers: int = 6,\n","        num_decoder_layers: int = 6,\n","        dim_feedforward: int = 2048,\n","        dropout: float = 0.1,\n","        pad_id: int = 0,\n","        share_embeddings: bool = False,\n","    ):\n","        super().__init__()\n","        self.pad_id = pad_id\n","        self.d_model = d_model\n","\n","        # Embeddings\n","        self.src_tok_emb = nn.Embedding(src_vocab_size, d_model, padding_idx=pad_id)\n","        if share_embeddings and (src_vocab_size == tgt_vocab_size):\n","            self.tgt_tok_emb = self.src_tok_emb\n","        else:\n","            self.tgt_tok_emb = nn.Embedding(tgt_vocab_size, d_model, padding_idx=pad_id)\n","\n","        self.pos_enc = PositionalEncoding(d_model, dropout=dropout)\n","\n","        # ---------\n","        # Encoder/Decoder layers (batch_first=True)\n","        # ---------\n","        self.encoder_layers = nn.ModuleList([\n","            nn.TransformerEncoderLayer(\n","                d_model=d_model,\n","                nhead=nhead,\n","                dim_feedforward=dim_feedforward,\n","                dropout=dropout,\n","                batch_first=True,\n","                norm_first=False,\n","            )\n","            for _ in range(num_encoder_layers)\n","        ])\n","        self.encoder_norm = nn.LayerNorm(d_model)\n","\n","        self.decoder_layers = nn.ModuleList([\n","            nn.TransformerDecoderLayer(\n","                d_model=d_model,\n","                nhead=nhead,\n","                dim_feedforward=dim_feedforward,\n","                dropout=dropout,\n","                batch_first=True,\n","                norm_first=False,\n","            )\n","            for _ in range(num_decoder_layers)\n","        ])\n","        self.decoder_norm = nn.LayerNorm(d_model)\n","\n","        # Output head\n","        self.generator = nn.Linear(d_model, tgt_vocab_size)\n","\n","        # Optional: tie output with target embedding\n","        self.tie_output = False\n","        if share_embeddings and (src_vocab_size == tgt_vocab_size):\n","            self.tie_output = True\n","            self.generator.weight = self.tgt_tok_emb.weight\n","\n","    # ---- helpers ----\n","    def _embed_src(self, src_tokens: torch.Tensor) -> torch.Tensor:\n","        src = self.src_tok_emb(src_tokens) * math.sqrt(self.d_model)\n","        return self.pos_enc(src)\n","\n","    def _embed_tgt(self, tgt_tokens: torch.Tensor) -> torch.Tensor:\n","        tgt = self.tgt_tok_emb(tgt_tokens) * math.sqrt(self.d_model)\n","        return self.pos_enc(tgt)\n","\n","    # ---- with layer traces ----\n","    def encode_with_layers(self, src_tokens: torch.Tensor, src_key_padding_mask: torch.Tensor | None = None):\n","        \"\"\"\n","        returns:\n","          memory: (B, S, D)\n","          enc_hiddens: list[(B,S,D)]  各層の出力\n","        \"\"\"\n","        x = self._embed_src(src_tokens)\n","        enc_hiddens = []\n","        for layer in self.encoder_layers:\n","            x = layer(x, src_key_padding_mask=src_key_padding_mask)\n","            enc_hiddens.append(x)\n","        x = self.encoder_norm(x)\n","        return x, enc_hiddens\n","\n","    def decode_with_layers(\n","        self,\n","        tgt_tokens: torch.Tensor,\n","        memory: torch.Tensor,\n","        tgt_mask: torch.Tensor | None = None,\n","        tgt_key_padding_mask: torch.Tensor | None = None,\n","        memory_key_padding_mask: torch.Tensor | None = None,\n","    ):\n","        \"\"\"\n","        returns:\n","          out: (B, T, D)\n","          dec_hiddens: list[(B,T,D)] 各層の出力\n","        \"\"\"\n","        y = self._embed_tgt(tgt_tokens)\n","        dec_hiddens = []\n","        for layer in self.decoder_layers:\n","            y = layer(\n","                y,\n","                memory,\n","                tgt_mask=tgt_mask,\n","                tgt_key_padding_mask=tgt_key_padding_mask,\n","                memory_key_padding_mask=memory_key_padding_mask,\n","            )\n","            dec_hiddens.append(y)\n","        y = self.decoder_norm(y)\n","        return y, dec_hiddens\n","\n","    # ---- original APIs (keep) ----\n","    def encode(self, src_tokens: torch.Tensor, src_key_padding_mask: torch.Tensor | None = None):\n","        memory, _ = self.encode_with_layers(src_tokens, src_key_padding_mask=src_key_padding_mask)\n","        return memory\n","\n","    def decode(\n","        self,\n","        tgt_tokens: torch.Tensor,\n","        memory: torch.Tensor,\n","        tgt_mask: torch.Tensor | None = None,\n","        tgt_key_padding_mask: torch.Tensor | None = None,\n","        memory_key_padding_mask: torch.Tensor | None = None,\n","    ):\n","        out, _ = self.decode_with_layers(\n","            tgt_tokens, memory,\n","            tgt_mask=tgt_mask,\n","            tgt_key_padding_mask=tgt_key_padding_mask,\n","            memory_key_padding_mask=memory_key_padding_mask,\n","        )\n","        return out\n","\n","    def forward(self, src_tokens: torch.Tensor, tgt_tokens: torch.Tensor):\n","        device = src_tokens.device\n","\n","        src_pad = make_padding_mask(src_tokens, self.pad_id)  # (B,S)\n","        tgt_pad = make_padding_mask(tgt_tokens, self.pad_id)  # (B,T)\n","\n","        tgt_len = tgt_tokens.size(1)\n","        tgt_mask = generate_square_subsequent_mask(tgt_len, device=device)  # (T,T)\n","\n","        memory = self.encode(src_tokens, src_key_padding_mask=src_pad)\n","        dec_out = self.decode(\n","            tgt_tokens,\n","            memory,\n","            tgt_mask=tgt_mask,\n","            tgt_key_padding_mask=tgt_pad,\n","            memory_key_padding_mask=src_pad,\n","        )\n","        logits = self.generator(dec_out)\n","        return logits\n","\n","\n","\n","# ----------------------------\n","# Quick sanity check\n","# ----------------------------\n","if __name__ == \"__main__\":\n","    B, src_len, tgt_len = 2, 7, 6\n","    src_vocab, tgt_vocab = 1000, 1200\n","    pad_id = 0\n","\n","    model = TransformerSeq2Seq(\n","        src_vocab_size=src_vocab,\n","        tgt_vocab_size=tgt_vocab,\n","        d_model=256,\n","        nhead=8,\n","        num_encoder_layers=3,\n","        num_decoder_layers=3,\n","        dim_feedforward=1024,\n","        dropout=0.1,\n","        pad_id=pad_id,\n","        share_embeddings=False,\n","    )\n","\n","    src = torch.randint(1, src_vocab, (B, src_len))\n","    tgt_in = torch.randint(1, tgt_vocab, (B, tgt_len))\n","    src[:, -1] = pad_id\n","    tgt_in[:, -1] = pad_id\n","\n","    # --- ここから “観測” ---\n","    device = src.device\n","    src_pad = make_padding_mask(src, pad_id)\n","    tgt_pad = make_padding_mask(tgt_in, pad_id)\n","    tgt_mask = generate_square_subsequent_mask(tgt_len, device=device)\n","\n","    memory, enc_h = model.encode_with_layers(src, src_key_padding_mask=src_pad)\n","    dec_out, dec_h = model.decode_with_layers(\n","        tgt_in, memory,\n","        tgt_mask=tgt_mask,\n","        tgt_key_padding_mask=tgt_pad,\n","        memory_key_padding_mask=src_pad,\n","    )\n","\n","    logits = model.generator(dec_out)\n","    ent = last_token_entropy(logits)\n","    ent_last_mean = last_token_entropy(logits)   # scalar\n","    dh_dec = layer_delta_h(dec_h)                # scalar（decoder側Δh）\n","\n","    controller = GSMCController()\n","    action = controller.decide({\n","        \"entropy\": ent_last_mean,\n","        \"delta_h\": dh_dec,\n","        \"phase\": \"coherence\",\n","        \"step_in_layer\": 0\n","    })\n","\n","    print(\"logits:\", logits.shape)\n","    print(\"entropy last mean:\", float(ent_last_mean))\n","    print(\"delta_h(dec):\", float(dh_dec))\n","    print(\"action:\", action)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SwPfOfEhcGhw","executionInfo":{"status":"ok","timestamp":1766011106163,"user_tz":-540,"elapsed":3892,"user":{"displayName":"零一真","userId":"13547062280887801150"}},"outputId":"8841c22d-5ff9-4310-f105-71d2180a84a2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["logits: torch.Size([2, 6, 1200])\n","entropy last mean: 6.91867208480835\n","delta_h(dec): 7.096216201782227\n","action: Action.STAY_STILLNESS\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n","  warnings.warn(\n","/tmp/ipython-input-3746010838.py:429: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n","Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n","  print(\"entropy last mean:\", float(ent_last_mean))\n"]}]}]}