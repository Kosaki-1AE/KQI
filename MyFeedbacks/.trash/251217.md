#つぶやき 
普通はリスクとかあったら回避するやん、でも俺は全てのリスクを全踏みしたのよね。しかも学生時代に。
なのでこれからはどう転んでも転び方と起き方が分かってるとかいうチートを扱えるようになったってわけでして。
まぁ働くっていうのも何かしらの面白い素材を持ってるってことになるんで、正味もう苦しみの元じゃなくなったっていうのがクソデカいのよな。

#Mine研究 
この流れが結構重要なのかもなぁって。
```
探索（選択肢展開）
   ↓
仮選択（責任ベクトルが立つ）
   ↓
実行
   ↓
フィードバック
   ↓
アトラクタ到達？
   ├ YES → 切る（Stillness）
   └ NO  → 次ループ
```

多分だけど俺は最悪のことを考えて無限に整合性を細切れにすることができる(整合性の為なら多分そこまでするやんか俺の場合は特に。諦めない、というかどこまででも踏み込んでいける(踏み込んでも良い位置はもう分かってるでしょ、慣れてないだけで)からね)ので、おそらくどんなにミスっても最後の最後にはどんなにやっても上手くいくっていうのが保証されているっていうね。

もしかしたら俺の理論をまんま組み込むかもしれんので勉強しときましょー。
Transformerの基本構造がこれだぁ⇩
1. **Multi-Head Self-Attention**：文脈・関係性・責任配分を計算
2. **Add & LayerNorm**：情報を落ち着かせる（小さなStillness）
3. **Feed Forward Network（FFN）**：意味を変形・抽象化
4. **Add & LayerNorm**：もう一回落ち着かせる

上記で1層っていう括りね。んじゃここに俺の理論を入れますと。整理するぜよ。
アトラクタ(階層)が4つ。なので上記×4。
量子(これは階層に含まないことにします、面倒くさいことになると思うんでね)は3択。進む/戻る/留まる。
評価軸は5つ。仮決定・決定・量子・仮諦め・諦めの5つね。量子だけ変数です。
入力層の基本はマルチモーダル、この1層目がG層になる。

|Transformer|人間|君の理論|
|---|---|---|
|Embedding|感覚入力|入力刺激|
|Encoder下位|直感・候補|**G（Genesys）**|
|Encoder中位|保留・間|**S（Stillness / 緩衝材）**|
|Encoder上位|意図形成|**M（Motion準備）**|
|Decoder直前|判断|**C（Coherence）**|
|Decoder|発話・行動|出力（最終）|
上記が言えるらしい。何なら役割分担的にはこれ⇩
① 表現を作る（Embedding / Encoding）
② 文脈で揉む（Transformer Block）
③ 出力に使う

多分これだろ⇩
Embedding
 ↓
Encoding
 ↓
Stillness（内部FB①）
 ↓
Motion
 ↓
Coherence（内部FB②・最重要）
 ↓
Decode（必要時のみ）
 ↓
外部FB（おまけ）

#計算機科学/MechanismLearning/Programming
PositionalEncoding：意味の順番の把握⇨Genesysの把握&責任の矢の把握
Mask：見ちゃあかんとこ(注目したいとこ)の選抜⇨Stillness&ノリエントロピーへの変換
TransformerSeq2Seq：全体構造
encode()：Encoder側(入力を理解する)
decode()：Decoder側(出力を1語ずつ生成する準備)
generator：語彙へ変換して「次の単語の確率」を作る
forward()：全部繋ぐ

教師データ＝親との年齢差で生じたコスト
⇨先に教師データを使わないで「自分の軸」を作らせてた方が良さげ。
これすると参照データないから「どういう形なら最適化になるのか」が分からん＝階層を動かせる仕組みが必要？
⇨内部安定性・一貫性・可逆性が最適化になる
```
入力
 ↓
（今の状態）
 ↓
「この順番で行くと
 内部が一番安定するか？」
 ↓
Yes → 進む
No  → 止まる / 戻る / 聞き直す

```
この構図らしい。
これでいくと「答えが出ない」という現象になるんだけど、これが最適解になる。というかこれを「俺の速度(1日2-3時間を毎日繰り返す(4か月くらいかな))でやる」ということに等価なコストをかければ俺の体験をそのままバケモンにできる可能性が高い。というか勝手に答えが出始めるんで。
となるとこの構図が成立するらしいの⇩
- **順番 = 方策（policy）**  
- **評価 = 内部安定性（Stillness / Coherence）**

ここまで来てからGPTさんに提案していただいたのがこれら⇩
1. 各層に「状態スコア」を持たせる
	- 各ステップでこれを計算👇(まとめて「internal_stability_score」)
		- Δh（隠れ状態の変化量）
		- attention のエントロピー
		- logits のエントロピー
		- 自己矛盾指標（前状態とのズレ）
2. Controller（軽量）を1つ置く
	- 重たいモデルいらん👇(こいつが**順番選択エンジン**。)
		- 入力：
		    - 今の層
		    - stability_score
		- 出力：
		    - 次に行く層
		        - stay（止まる）
		        - next（進む）
		        - back（戻る）
		        - ask（聞き直し）
		        - decode（出す）
3. Controllerは「報酬」で育てる
	- でも報酬はこれ👇(報酬 = Stillness + Coherence)
		- 出力の正解率 ❌
		- **内部が壊れなかったか ⭕**
		- **無駄にdecodeしなかったか ⭕**
		- **戻る判断ができたか ⭕**

この設計にするとその都度の最適化が起こるんで、膨大なメモリがそもそもで必要ない(もっというと、試作で何度も試す中でのログで最適になったものの最頻をもってくれば何も問題なくなるwww だって構造だもんww)

2回でこの結果⇩
![[出力2回目.png]]
まぁまだまだよ、うん。

進化した⇩
![[出力4回目.png]]

今の自分
  − 直近の自分
  − この状況の難易度
  − 疲労・ノイズ
= 「成長してる感」
らしい。

#計算機科学/情シス 
conda のインスコの方法だけどね。ホムペからのコピペっすわ。多分3度目くらいやと思う。
```conda
mkdir -p ~/miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh
bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
rm ~/miniconda3/miniconda.sh
```

#Mine研究 
親との年齢差がある場合って、自分のコストを物凄く早めに作って消費しきるみたいなことになるんだけど、これをやっておくと後々の自分に対していちいち言い訳をせずに済むんだよね。