本日の2限に山本研での発表会がありまして。そこで出てきた「Attention is All You Need」と

いう論文(これが2024年度のノーベル物理学賞取った)をかなり聞いたので、調べてみようと思い

ます 

中身で大切だとされているのが「Attention」と「Transformer」の2つの概念。 

これは主に生成AIで使われてるんだけどさ、一応全部に活かせはするってのがこれ↓ 
• Transformer：各単語への最も深い関係がありそうなものを検索してその中でも最も関係性が

高いものを関連付ける 

• Attention：それぞれの関係性の深さのこと 

学習回数が多いもの：ディープラーニングと呼ばれる 

これが初めて扱うちゃんとした論文になるので、ここに緩急を混ぜ込めたら一番良きと思うの

で、色々やってみようかと思います。 

なおここは基本的に論文を書いていく場にしよかなと。その方が後々楽になるかなーと思いまし

て。 

と思ったんだけど、やっぱやめとく。これ作っちゃうとめんどくさそうなので。 

